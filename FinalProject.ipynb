{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucasNH/CSC413-Final-Project/blob/main/FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B5oBvcYdqXxN"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# files.upload() # Upload your kaggle API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDXnFD7CsGXq"
      },
      "outputs": [],
      "source": [
        "# Installing required packages\n",
        "# !pip install arxiv\n",
        "# !pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4ozHOW-qgYe"
      },
      "outputs": [],
      "source": [
        "# !mkdir -p ~/.kaggle\n",
        "# !mv kaggle.json ~/.kaggle/\n",
        "\n",
        "# !chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "# # Create the directories for original data\n",
        "# !rm -rf ./dataset/\n",
        "# !kaggle datasets download -d Cornell-University/arxiv\n",
        "# !unzip arxiv.zip > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4XtGcrisTHP"
      },
      "outputs": [],
      "source": [
        "# !ls -lah /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsOtNuu3JzS9"
      },
      "source": [
        "## Part 1\n",
        "\n",
        "Download the files `reuters_train.txt` and `reuters_valid.txt`, and upload them to Google Drive.\n",
        "\n",
        "Then, mount Google Drive from your Google Colab notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Hr67PSFAOWFE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57FvL2tRNbe2",
        "outputId": "0b7014f5-5df2-4b16-d10c-233e2df42c29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext==0.6.0 in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.31.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.1.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (0.1.99)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext==0.6.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxGcK1xfJ9-l",
        "outputId": "1357c45f-44e6-4416-c83d-0f7469690f7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "# train_path = '/content/gdrive/My Drive/Colab Notebooks/data/arxiv_train.txt'\n",
        "# valid_path = '/content/gdrive/My Drive/Colab Notebooks/data/arxiv_valid.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GvKfMrNgsMMn"
      },
      "outputs": [],
      "source": [
        "file_path =  '/content/gdrive/MyDrive/Colab Notebooks/data/arxiv.txt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPijuGS6JzS-"
      },
      "source": [
        "We will be using PyTorch's `torchtext` utilities to help us load, process,\n",
        "and batch the data. This package is useful, but takes a bit of time to get\n",
        "used to.\n",
        "\n",
        "We'll be using a `TabularDataset` to load our data, which works well on structured\n",
        "CSV data with fixed columns (e.g. a column for the sequence, a column for the label). Our tabular dataset\n",
        "is even simpler: we have no labels, just some text. So, we are treating our data as a table with one field\n",
        "representing our sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ER2T6iRdJzS-"
      },
      "outputs": [],
      "source": [
        "import torchtext\n",
        "\n",
        "# Tokenization function to separate a headline into words\n",
        "def tokenize_headline(headline):\n",
        "    \"\"\"Returns the sequence of words in the string headline. We also\n",
        "    prepend the \"<bos>\" or beginning-of-string token, and append the\n",
        "    \"<eos>\" or end-of-string token to the headline.\n",
        "    \"\"\"\n",
        "    return (\"<bos> \" + headline + \" <eos>\").split()\n",
        "\n",
        "# Data field (column) representing our *text*.\n",
        "\n",
        "text_field = torchtext.data.Field(\n",
        "    sequential=True,            # this field consists of a sequence\n",
        "    tokenize=tokenize_headline, # how to split sequences into words\n",
        "    include_lengths=True,       # to track the length of sequences, for batching\n",
        "    batch_first=True,           # similar to batch_first=True in nn.RNN demonstrated in lecture\n",
        "    use_vocab=True)             # to turn each character into an integer index\n",
        "\n",
        "full_dataset = torchtext.data.TabularDataset(\n",
        "    path=file_path,                 # data file path\n",
        "    format=\"tsv\",                   # fields are separated by a tab\n",
        "    fields=[('title', text_field)]) # list of fields (we have only one)\n",
        "\n",
        "# Split the dataset into train and validation sets (80/20 split)\n",
        "train_data, val_data = full_dataset.split(split_ratio=0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmq5YS2rJzS_"
      },
      "source": [
        "### Part (a) -- 2 points\n",
        "\n",
        "Draw histograms of the number of words per headline in our training set.\n",
        "Excluding the `<bos>` and `<eos>` tags in your computation.\n",
        "Explain why we would be interested in such histograms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "70B87MVUJzS_",
        "outputId": "e5675270-7975-4277-fd17-e069be4f7a4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['<bos>', 'Bosonic', 'characters', 'of', 'atomic', 'Cooper', 'pairs', 'across', 'resonance', '<eos>']\n",
            "['<bos>', 'Calculation', 'of', 'prompt', 'diphoton', 'production', 'cross', 'sections', 'at', 'Tevatron', 'and', 'LHC', 'energies', '<eos>']\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Include your histogram and your written explanations\n",
        "\n",
        "# Here is an example of how to plot a histogram in matplotlib:\n",
        "# plt.hist(np.random.normal(0, 1, 40), bins=)\n",
        "\n",
        "word_counts = [len(x.title) - 2 for x in train_data] # Exclude <bos>, <eos>\n",
        "plt.hist(word_counts, bins=10, range=(0, 40))\n",
        "\n",
        "# Here are some sample code that uses the train_data object:\n",
        "print(train_data[5].title)\n",
        "for example in train_data:\n",
        "    print(example.title)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJk3wBhDJzS_"
      },
      "source": [
        "### Part (b) -- 2 points\n",
        "\n",
        "How many distinct words appear in the training data?\n",
        "Exclude the `<bos>` and `<eos>` tags in your computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW7k5B1SJzS_",
        "outputId": "bbbe4089-b66c-49f3-a3c5-98a06f9cbd09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distinct Words: 253578\n"
          ]
        }
      ],
      "source": [
        "# Report your values here. Make sure that you report the actual values,\n",
        "# and not just the code used to get those values\n",
        "\n",
        "# You might find the python class Counter from the collections package useful\n",
        "from collections import Counter\n",
        "words_cnt = Counter()\n",
        "for x in train_data:\n",
        "  words_cnt.update(x.title[1:-1])\n",
        "\n",
        "print(f'Distinct Words: {len(words_cnt)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1EKAI9aJzS_"
      },
      "source": [
        "### Part (c) -- 2 points\n",
        "\n",
        "The distribution of *words* will have a long tail, meaning that there are some words\n",
        "that will appear very often, and many words that will appear infrequently. How many words\n",
        "appear exactly once in the training set? Exactly twice?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_5JJ5RCJzTA",
        "outputId": "78f0b384-0c81-4ad7-9af1-6e13fb70e9ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appearing Once: ['SalSi', 'PanoVOS', 'LHRM', 'Pli', 'PyStokes', 'Grillakis', 'Machedon', 'Margetis', 'multibranching', 'J082053']\n",
            "Appearing Twice: ['Multimodular', 'Finalized', 'Waldenfels', 'duopolies', '9PN', 'Deinterleaver', 'Hyponormality', 'temerature', 'CygnusX', 'THERMUS']\n"
          ]
        }
      ],
      "source": [
        "# Report your values here. Make sure that you report the actual values,\n",
        "# and not just the code used to get those values\n",
        "\n",
        "\n",
        "word_freqs = [(word, count) for (word, count) in words_cnt.items()]\n",
        "\n",
        "appear_once = [word for (word, count) in word_freqs if count == 1]\n",
        "appear_twice = [word for (word, count) in word_freqs if count == 2]\n",
        "\n",
        "print(f\"Appearing Once: {appear_once[:10]}\")\n",
        "print(f\"Appearing Twice: {appear_twice[:10]}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmhkWz_kJzTA"
      },
      "source": [
        "### Part (d) -- 2 points\n",
        "\n",
        "Explain why we may wish to replace these infrequent\n",
        "words with an `<unk>` tag, instead of learning embeddings for these rare words.\n",
        "(Hint: Consider words in the validation set that might not appear in training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgeFPNdbJzTA"
      },
      "outputs": [],
      "source": [
        "# Include your explanation here\n",
        "\n",
        "# Words in the validation set that do not appear during training will not have have an associated embeddings.\n",
        "# We can obtain an embedding for thses unseen words by substituting them with <unk>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftZ5PnskJzTA"
      },
      "source": [
        "### Part (e) -- 2 points\n",
        "\n",
        "We will only model the top 9995 words in the training set, excluding the tags\n",
        "`<bos>`, `<eos>`, and other possible tags we haven't mentioned yet\n",
        "(including those, we will have a vocabulary size of exactly 10000 tokens).\n",
        "\n",
        "What percentage of word occurrences will be supported? Alternatively, what percentage\n",
        "of word occurrences in the training set will be set to the `<unk>` tag?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHPB4BQcJzTA",
        "outputId": "dbb2bf4e-af3c-4f65-a46e-12d0efa75410"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of occurrences supported: 0.9182234230469967\n"
          ]
        }
      ],
      "source": [
        "# Report your values here. Make sure that you report the actual values,\n",
        "# and not just the code used to get those values\n",
        "\n",
        "top_words = words_cnt.most_common(9995)\n",
        "total = len(list(words_cnt.elements()))\n",
        "\n",
        "total_kept = 0\n",
        "for _, cnt in top_words:\n",
        "  total_kept += cnt\n",
        "\n",
        "print(f'Percentage of occurrences supported: {total_kept / total}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKjIXeMcJzTA"
      },
      "source": [
        "Our `torchtext` package will help us keep track of our list of unique words, known\n",
        "as a **vocabulary**. A vocabulary also assigns a unique integer index to each word.\n",
        "You can interpret these indices as sparse representations of one-hot vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xy0zlLGtJzTA",
        "outputId": "d479dfa9-bf46-497c-99cf-587acc96c442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "$\n",
            "10000\n",
            "<unk>\n",
            "<pad>\n"
          ]
        }
      ],
      "source": [
        "# Build the vocabulary based on the training data. The vocabulary\n",
        "# can have at most 9997 words (9995 words + the <bos> and <eos> token)\n",
        "text_field.build_vocab(train_data, max_size=9997)\n",
        "\n",
        "# This vocabulary object will be helpful for us\n",
        "vocab = text_field.vocab\n",
        "print(vocab.stoi[\"hello\"]) # for instances, we can convert from string to (unique) index\n",
        "print(vocab.itos[10])      # ... and from word index to string\n",
        "\n",
        "# The size of our vocabulary is actually 10000\n",
        "vocab_size = len(text_field.vocab.stoi)\n",
        "print(vocab_size) # should be 10000\n",
        "\n",
        "\n",
        "# The reason is that torchtext adds two more tokens for us:\n",
        "print(vocab.itos[0]) # <unk> represents an unknown word not in our vocabulary\n",
        "print(vocab.itos[1]) # <pad> will be used to pad short sequences for batching"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp8DEK0uNOHG"
      },
      "source": [
        "## Question 2\n",
        "\n",
        "Building a text autoencoder is a little more complicated than an image autoencoder, so\n",
        "we'll need to thoroughly understand the model that we want to build before actually building\n",
        "our model. Note that the best and fastest way to complete this assignment is to spend a *lot*\n",
        "of time upfront understanding the architecture. The explanations are quite dense, and you\n",
        "might need to stop every sentence or two to understand what's going on.\n",
        "You won't feel productive for a while since you won't be writing code,\n",
        "but this initial investment will help you become more productive later on.\n",
        "Understanding this architecture will also help you understand other machine learning\n",
        "papers you might come across. So, take a deep breath, and let's do this!\n",
        "\n",
        "Here is a diagram showing our desired architecture:\n",
        "\n",
        "![](https://github.com/LucasNH/CSC413-Final-Project/blob/model-training/p4model.png?raw=1){ width=90% }\n",
        "\n",
        "<img src=\"https://github.com/LucasNH/CSC413-Final-Project/blob/model-training/p4model.png?raw=1\" width=\"95%\" />\n",
        "\n",
        "There are two main components to the model: the **encoder** and the **decoder**.\n",
        "As always with neural networks, we'll first describe how to make\n",
        "**predictions** with of these components. Let's get started:\n",
        "\n",
        "The **encoder** will take a sequence of words (a headline) as *input*, and produce an\n",
        "embedding (a vector) that represents the entire headline. In the diagram above,\n",
        "the vector ${\\bf h}^{(7)}$ is the vector embedding containing information about\n",
        "the entire headline.  This portion is very similar\n",
        "to the sentiment analysis RNN that we discussed in lecture (but without the fully-connected\n",
        "layer that makes a prediction).\n",
        "\n",
        "The **decoder** will take an embedding (in the diagram, the vector ${\\bf h}^{(7)}$) as input,\n",
        "and uses a separate RNN to **generate a sequence of words**. To generate a sequence of words,\n",
        "the decoder needs to do the following:\n",
        "\n",
        "1) Determine the previous word that was generated. This previous word will act as ${\\bf x}^{(t)}$\n",
        "   to our RNN, and will be used to update the hidden state ${\\bf m}^{(t)}$. Since each of our\n",
        "   sequences begin with the `<bos>` token, we'll set ${\\bf x}^{(1)}$ to be the `<bos>` token.\n",
        "2) Compute the updates to the hidden state ${\\bf m}^{(t)}$ based on the previous hidden state\n",
        "   ${\\bf m}^{(t-1)}$ and ${\\bf x}^{(t)}$. Intuitively, this hidden state vector ${\\bf m}^{(t)}$\n",
        "   is a representation of *all the words we still need to generate*.\n",
        "3) We'll use a fully-connected layer to take a hidden state ${\\bf m}^{(t)}$, and determine\n",
        "   *what the next word should be*. This fully-connected layer solves a *classification problem*,\n",
        "   since we are trying to choose a word out of $K=10000$ distinct words. As in a classification\n",
        "   problem, the fully-connected neural network will compute a *probability distribution* over\n",
        "   these 10,000 words. In the diagram, we are using ${\\bf z}^{(t)}$ to represent the logits,\n",
        "   or the pre-softmax activation values representing the probability distribution.\n",
        "4) We will need to *sample* an actual word from this probability distribution ${\\bf z}^{(t)}$.\n",
        "   We can do this in a number of ways, which we'll discuss in question 3. For now, you can\n",
        "   imagine your favourite way of picking a word given a distribution over words.\n",
        "5) This word we choose will become the next input ${\\bf x}^{(t+1)}$ to our RNN, which is used\n",
        "   to update our hidden state ${\\bf m}^{(t+1)}$---i.e. to determine what are the remaining\n",
        "   words to be generated.\n",
        "\n",
        "We can repeat this process until we see an `<eos>` token generated, or until the generated\n",
        "sequence becomes too long.\n",
        "\n",
        "Unfortunately, we can't *train* this autoencoder in the way we just described. That is,\n",
        "we can't just compare our generated sequence with our ground-truth sequence, and get\n",
        "gradients. Both sequences are **discrete** entities, so we won't be able to compute\n",
        "gradients at all! In particular, **sampling is a discrete process**, and so we won't be\n",
        "able to back-propagate through any kind of sampling that we do.\n",
        "\n",
        "You might wonder whether we can get away with computing gradients by comparing the\n",
        "distributions ${\\bf z}^{(t)}$ with the ground truth words at each time step. Like any\n",
        "multi-class classification problem, we can represent the ground-truth words as a one-hot\n",
        "vector, and use the cross-entropy loss.\n",
        "\n",
        "In theory, we can do this. In practice, there are a few issues. One is that the generated\n",
        "sequence might be longer or shorter than the actual sequence, meaning that there may\n",
        "be more/fewer ${\\bf z}^{(t)}$s than ground-truth words. Another more insidious issue\n",
        "is that the **gradients will become very high-variance and unstable**, because\n",
        "**early mistakes will easily throw the model off-track**. Early in training,\n",
        "our model is unlikely to produce the right answer in step $t=1$, so the gradients\n",
        "we obtain based on the other time steps will not be very useful.\n",
        "\n",
        "At this point, you might have some ideas about \"hacks\" we can use to make training\n",
        "work. Fortunately, there is one very well-established solution called\n",
        "**teacher forcing** which we can use for training:\n",
        "instead of *sampling* the next word based on ${\\bf z}^{(t)}$, we will forgo sampling,\n",
        "and use the **ground truth** ${\\bf x}^{(t)}$ in the next step.\n",
        "\n",
        "Here is a diagram showing how we can use **teacher forcing** to train our model:\n",
        "\n",
        "![](https://github.com/LucasNH/CSC413-Final-Project/blob/model-training/p4model_tf.png?raw=1){ width=90% }\n",
        "\n",
        "<img src=\"https://github.com/LucasNH/CSC413-Final-Project/blob/model-training/p4model_tf.png?raw=1\" width=\"95%\" />\n",
        "\n",
        "We will use the RNN generator to compute the logits\n",
        "${\\bf z}^{(1)},{\\bf z}^{(2)},  \\cdots {\\bf z}^{(T)}$. These distributions\n",
        "can be compared to the ground-truth words using the cross-entropy loss.\n",
        "The loss function for this model will be the sum of the losses across each $t$.\n",
        "(This is similar to what we did in a pixel-wise prediction problem.)\n",
        "\n",
        "We'll train the encoder and decoder model simultaneously. There are several components\n",
        "to our model that contain tunable weights:\n",
        "\n",
        "- The word embedding that maps a word to a vector representation.\n",
        "  In theory, we could use GloVe embeddings, or initialize our parameters to\n",
        "  GloVe embeddings. To prevent students who don't have Colab access\n",
        "  from having to download a 1GB file, we won't do that.\n",
        "  The word embedding component is represented with blue arrows in the diagram.\n",
        "- The encoder RNN (which will use Gated Recurrent Units) that computes the\n",
        "  embedding over the entire headline. The encoder RNN\n",
        "  is represented with black arrows in the diagram.\n",
        "- The decoder RNN (which will also use Gated Recurrent Units) that computes\n",
        "  hidden states, which are vectors representing what words are to be generated.\n",
        "  The decoder RNN is represented with gray arrows in the diagram.\n",
        "- The **projection MLP** (one fully-connected layer) that computes\n",
        "  a distribution over the next word to generate, given a decoder RNN hidden\n",
        "  state.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b1T26K9VWUS"
      },
      "source": [
        "### Part (a) -- 10 pts\n",
        "\n",
        "Complete the code for the AutoEncoder class below by:\n",
        "\n",
        "1. Filling in the missing numbers in the `__init__` method using\n",
        "   the parameters `vocab_size`, `emb_size`, and `hidden_size`. (4 points)\n",
        "2. Complete the `forward` method, which uses teacher forcing\n",
        "   and computes the logits $z^{(t)}$ of the reconstruction of\n",
        "   the sequence. (4 points)\n",
        "\n",
        "You should first try to understand the `encode` and `decode` methods,\n",
        "which are written for you. The `encode` method mimics a discriminative\n",
        "RNN (see the sentiment analysis notebook).  The `decode` method is\n",
        "a generative RNN and is a bit more complex (see the text generation\n",
        "tutorial notebook).  You might want to scroll down to the\n",
        "`sample_sequence` function to see how this function will be called.\n",
        "\n",
        "You can (but don't have to) use the `encode` and `decode` method in\n",
        "your `forward` method. In either case, be very careful of the input\n",
        "that you feed into ether `decode` or to `self.decoder_rnn`.\n",
        "Refer to the teacher-forcing diagram."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Sb4_VBvHNOHG"
      },
      "outputs": [],
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_size, hidden_size):\n",
        "        \"\"\"\n",
        "        A text autoencoder. The parameters\n",
        "            - vocab_size: number of unique words/tokens in the vocabulary\n",
        "            - emb_size: size of the word embeddings $x^{(t)}$\n",
        "            - hidden_size: size of the hidden states in both the\n",
        "                           encoder RNN ($h^{(t)}$) and the\n",
        "                           decoder RNN ($m^{(t)}$)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(num_embeddings=vocab_size, # TODO\n",
        "                                  embedding_dim=emb_size)  # TODO\n",
        "        self.encoder_rnn = nn.GRU(input_size=emb_size, #TODO\n",
        "                                  hidden_size=hidden_size, #TODO\n",
        "                                  batch_first=True)\n",
        "        self.decoder_rnn = nn.GRU(input_size=emb_size, #TODO\n",
        "                                  hidden_size=hidden_size, #TODO\n",
        "                                  batch_first=True)\n",
        "        self.proj = nn.Linear(in_features=hidden_size, # TODO\n",
        "                              out_features=vocab_size) # TODO\n",
        "\n",
        "    def encode(self, inp):\n",
        "        \"\"\"\n",
        "        Computes the encoder output given a sequence of words.\n",
        "        \"\"\"\n",
        "        emb = self.embed(inp)\n",
        "        out, last_hidden = self.encoder_rnn(emb)\n",
        "        return last_hidden\n",
        "\n",
        "    def decode(self, inp, hidden=None):\n",
        "        \"\"\"\n",
        "        Computes the decoder output given a sequence of words, and\n",
        "        (optionally) an initial hidden state.\n",
        "        \"\"\"\n",
        "        emb = self.embed(inp)\n",
        "        out, last_hidden = self.decoder_rnn(emb, hidden)\n",
        "        out_seq = self.proj(out)\n",
        "        return out_seq, last_hidden\n",
        "\n",
        "    def forward(self, inp):\n",
        "        \"\"\"\n",
        "        Compute both the encoder and decoder forward pass\n",
        "        given an integer input sequence inp with shape [batch_size, seq_length],\n",
        "        with inp[a,b] representing the (index in our vocabulary of) the b-th word\n",
        "        of the a-th training example.\n",
        "\n",
        "        This function should return the logits $z^{(t)}$ in a tensor of shape\n",
        "        [batch_size, seq_length - 1, vocab_size], computed using *teaching forcing*.\n",
        "\n",
        "        The (seq_length - 1) part is not a typo. If you don't understand why\n",
        "        we need to subtract 1, refer to the teacher-forcing diagram above.\n",
        "        \"\"\"\n",
        "\n",
        "        last_hidden = self.encode(inp)\n",
        "        # print(last_hidden.shape) # Should be [1, batch_size, hidden_size]\n",
        "\n",
        "        # Why do we have L - 1 logits?\n",
        "        # We do not pass the <eos> token to the Autoencoder, as there is no\n",
        "        # \"next word\" to sample.\n",
        "\n",
        "        out_seq, last_hidden = self.decode(inp, last_hidden)\n",
        "        # print(out_seq.shape) # should be [batch_size, seq_length, vocab_size]\n",
        "\n",
        "        return out_seq[:, :-1, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur-7r4v9WFnZ",
        "outputId": "ac4df557-7635-4daa-a79a-6300a92a08c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 100, 128])\n",
            "torch.Size([100, 61, 10000])\n"
          ]
        }
      ],
      "source": [
        "# Emulating the forward pass on a batch of examples\n",
        "\n",
        "model = AutoEncoder(vocab_size, 128, 128)\n",
        "# Load the dataset in batches of 100 examples\n",
        "train_dataloader = torchtext.data.Iterator(train_data, 100,\n",
        "                                           train=True, repeat=True,\n",
        "                                           shuffle=True, device=None)\n",
        "\n",
        "X = next(iter(train_dataloader)).title[0]\n",
        "# print(X.shape)\n",
        "last_hidden = model.encode(X)\n",
        "\n",
        "print(last_hidden.shape) # Remove 1 in dim 0\n",
        "\n",
        "out_seq, last_hidden = model.decode(X, last_hidden)\n",
        "print(out_seq.shape)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ebrpb2RcNOHG"
      },
      "source": [
        "### Part (b) -- 5 pts\n",
        "\n",
        "To check that your model is set up correctly, we'll train our AutoEncoder\n",
        "neural network for at least 300 iterations to memorize this sequence:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bieULfbzNOHG"
      },
      "source": [
        "We are looking for the way that you set up your loss function\n",
        "corresponding to the figure above.\n",
        "**Be very careful of off-by-ones.**\n",
        "\n",
        "Note that the Cross Entropy Loss expects a rank-2 tensor as its first\n",
        "argument, and a rank-1 tensor as its second argument. You will\n",
        "need to properly reshape your data to be able to compute the loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lqYG47jNOHG"
      },
      "outputs": [],
      "source": [
        "model = AutoEncoder(vocab_size, 128, 128)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "batch_stream = iter(train_dataloader)\n",
        "\n",
        "for it in range(300):\n",
        "    optimizer.zero_grad()\n",
        "    # Get a batch of examples. The shape is [B, L]\n",
        "    X = next(batch_stream).title[0]\n",
        "    logits = model.forward(X) # output logits from the decoder [B, L - 1, vocab_size]\n",
        "    logits = torch.permute(logits, (0, 2, 1)) # correct shape for loss fn is [B, vocab_size, L - 1]\n",
        "    targets = X[:,1:] # Shape is [B, L - 1] (we don't generate the first token in the input sequence, <bos>)\n",
        "\n",
        "    # TODO\n",
        "    loss = criterion(logits, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (it+1) % 50 == 0:\n",
        "        print(\"[Iter %d] Loss %f\" % (it+1, float(loss)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpx5r7LSwr5c"
      },
      "source": [
        "# Denoising Autoencoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_xlIA4zxQGJ"
      },
      "source": [
        "dd### Part (b) -- 2pt\n",
        "\n",
        "We will add noise to our headlines using a few different techniques:\n",
        "\n",
        "1. Shuffle the words in the headline, taking care that words don't end up too far from where they were initially\n",
        "2. Drop (remove) some words\n",
        "3. Replace some words with a blank word (a `<pad>` token)\n",
        "4. Replace some words with a random word\n",
        "\n",
        "The code for adding these types of noise is provided for you:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "tAMl3bRnu5MJ"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_randomize(headline,\n",
        "                           drop_prob=0.1,  # probability of dropping a word\n",
        "                           blank_prob=0.1, # probability of \"blanking\" out a word\n",
        "                           sub_prob=0.1,   # probability of substituting a word with a random one\n",
        "                           shuffle_dist=3): # maximum distance to shuffle a word\n",
        "    \"\"\"\n",
        "    Add 'noise' to a headline by slightly shuffling the word order,\n",
        "    dropping some words, blanking out some words (replacing with the <pad> token)\n",
        "    and substituting some words with random ones.\n",
        "    \"\"\"\n",
        "    title = [vocab.stoi[w] for w in title.split()]\n",
        "    n = len(title)\n",
        "    # shuffle\n",
        "    title = [title[i] for i in get_shuffle_index(n, shuffle_dist)]\n",
        "\n",
        "    new_title = [vocab.stoi['<bos>']]\n",
        "    for w in title:\n",
        "        if random.random() < drop_prob:\n",
        "            # drop the word\n",
        "            pass\n",
        "        elif random.random() < blank_prob:\n",
        "            # replace with blank word\n",
        "            new_title.append(vocab.stoi[\"<pad>\"])\n",
        "        elif random.random() < sub_prob:\n",
        "            # substitute word with another word\n",
        "            new_title.append(random.randint(0, vocab_size - 1))\n",
        "        else:\n",
        "            # keep the original word\n",
        "            new_title.append(w)\n",
        "    new_title.append(vocab.stoi['<eos>'])\n",
        "    return new_title\n",
        "\n",
        "def get_shuffle_index(n, max_shuffle_distance):\n",
        "    \"\"\" This is a helper function used to shuffle a headline with n words,\n",
        "    where each word is moved at most max_shuffle_distance. The function does\n",
        "    the following:\n",
        "       1. start with the *unshuffled* index of each word, which\n",
        "          is just the values [0, 1, 2, ..., n]\n",
        "       2. perturb these \"index\" values by a random floating-point value between\n",
        "          [0, max_shuffle_distance]\n",
        "       3. use the sorted position of these values as our new index\n",
        "    \"\"\"\n",
        "    index = np.arange(n)\n",
        "    perturbed_index = index + np.random.rand(n) * 3\n",
        "    new_index = sorted(enumerate(perturbed_index), key=lambda x: x[1])\n",
        "    return [index for (index, pert) in new_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "YaZ9Is5Mwxvz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class DenoisAdversarialAutoencoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_size, hidden_size, lambda_param):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder, Decoder, and Discriminator from the provided AutoEncoder class\n",
        "        self.autoencoder = AutoEncoder(vocab_size, emb_size, hidden_size)\n",
        "\n",
        "        # Discriminator network\n",
        "        self.discriminator = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.lambda_param = lambda_param\n",
        "\n",
        "    def encode(self, inp):\n",
        "        return self.autoencoder.encode(inp)\n",
        "\n",
        "    def decode(self, inp, hidden=None):\n",
        "        return self.autoencoder.decode(inp, hidden)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        return self.autoencoder(inp)\n",
        "\n",
        "    def adversarial_loss(self, z_prior, z_encoder):\n",
        "\n",
        "      real_labels = torch.ones_like(z_prior[:, :, :1])\n",
        "      fake_labels = torch.zeros_like(z_encoder[:, :, :1])\n",
        "\n",
        "\n",
        "      discriminator_linear = nn.Linear(1, 1)\n",
        "\n",
        "\n",
        "      adv_loss = nn.BCEWithLogitsLoss()  # Use BCEWithLogitsLoss for stability\n",
        "      d_loss = adv_loss(discriminator_linear(z_prior[:, :, :1]), real_labels) + adv_loss(discriminator_linear(z_encoder[:, :, :1]), fake_labels)\n",
        "\n",
        "\n",
        "      g_loss = adv_loss(discriminator_linear(z_encoder[:, :, :1]), real_labels)\n",
        "\n",
        "      return d_loss, self.lambda_param * g_loss\n",
        "\n",
        "\n",
        "\n",
        "    def train_step(self, inp):\n",
        "\n",
        "        z_encoder = self.encode(inp)\n",
        "        z_prior = torch.randn_like(z_encoder)\n",
        "\n",
        "\n",
        "        d_loss, g_loss = self.adversarial_loss(z_prior, z_encoder)\n",
        "\n",
        "\n",
        "        recon_loss = nn.CrossEntropyLoss()\n",
        "        logits = self.autoencoder(inp)\n",
        "        rec_loss = recon_loss(logits.view(-1, logits.size(2)), inp[:, 1:].contiguous().view(-1))\n",
        "\n",
        "\n",
        "        total_loss = rec_loss - d_loss - g_loss\n",
        "\n",
        "\n",
        "        self.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        return total_loss.item()\n",
        "\n",
        "\n",
        " # Replace with your actual vocabulary size\n",
        "emb_size = 128  # Replace with your desired embedding size\n",
        "hidden_size = 128  # Replace with your desired hidden size\n",
        "lambda_param = 0.1  # Replace with your desired lambda value\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgYA0ntFmWua"
      },
      "source": [
        "## Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "v9S7B_tayGHF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "training = False\n",
        "\n",
        "if training:\n",
        "    model = DenoisAdversarialAutoencoder(vocab_size, emb_size, hidden_size, lambda_param)\n",
        "\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    batch_stream = iter(train_dataloader)\n",
        "\n",
        "    for it in range(300):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        X = next(batch_stream).title[0]\n",
        "\n",
        "\n",
        "        logits = model(X)\n",
        "\n",
        "\n",
        "        logits = torch.permute(logits, (0, 2, 1))  # [B, vocab_size, L - 1]\n",
        "        targets = X[:, 1:]  # Shape is [B, L - 1] (we don't generate the first token in the input sequence, <bos>)\n",
        "\n",
        "\n",
        "        loss_rec = criterion(logits, targets)\n",
        "\n",
        "\n",
        "        z_encoder = model.encode(X)\n",
        "        z_prior = torch.randn_like(z_encoder)\n",
        "        d_loss, g_loss = model.adversarial_loss(z_prior, z_encoder)\n",
        "\n",
        "\n",
        "        loss = loss_rec - d_loss - g_loss\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (it + 1) % 50 == 0:\n",
        "            print(\"[Iter %d] Recon Loss %f | D Loss %f | G Loss %f\" % (it + 1, float(loss_rec), float(d_loss), float(g_loss)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "IQoETJxvhaqP"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "if training:\n",
        "    torch.save(model.state_dict(), 'model.pth')\n",
        "\n",
        "# Load the model\n",
        "# loaded_model = DenoisAdversarialAutoencoder(vocab_size, emb_size, hidden_size, lambda_param)\n",
        "# loaded_model.load_state_dict(torch.load('model.pth'))\n",
        "\n",
        "# baseline_model = AutoEncoder(vocab_size, emb_size, hidden_size)\n",
        "loaded_model = torch.load(\"model_baseline.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cos = nn.CosineSimilarity(dim=1, eps=1e-6)"
      ],
      "metadata": {
        "id": "AxPEcpxGzZoB"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = torchtext.data.BucketIterator(train_data, 32,\n",
        "                                           train=True, repeat=True,\n",
        "                                           shuffle=True, device=None)\n",
        "\n",
        "X = next(iter(train_dataloader)).title[0]\n",
        "\n",
        "\n",
        "embeddings_dictionary = {}\n",
        "\n",
        "# print(X)\n",
        "\n",
        "for title in X:\n",
        "    embedding = loaded_model.encode(title)\n",
        "    if embedding in embeddings_dictionary:\n",
        "        embeddings_dictionary[embedding].append(title)\n",
        "    else:\n",
        "        embeddings_dictionary[embedding] = [title]"
      ],
      "metadata": {
        "id": "bs0jhj-On_IJ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def l_emb_size_norm(a, b, emb_size):\n",
        "    distance = 0\n",
        "    for i in range(emb_size):\n",
        "        distance += ((a[i].item() - b[i].item()) ** emb_size)\n",
        "    distance ** (1 / emb_size)\n",
        "    return distance"
      ],
      "metadata": {
        "id": "0uTUsE7YyOVq"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(embeddings_dictionary)\n",
        "\n",
        "target_embd = torch.tensor([-1.0000, -1.0000, -0.9136,  1.0000, -1.0000,  1.0000, -0.5133, -0.9744,\n",
        "         -1.0000,  0.8250,  0.3641,  1.0000, -1.0000,  0.7279, -0.7730,  1.0000,\n",
        "          1.0000,  0.1633,  0.2159, -0.3960, -0.9996, -0.9841,  0.9816,  1.0000,\n",
        "         -0.4607,  1.0000,  0.9734,  0.1995,  0.9950,  1.0000, -1.0000, -0.9969,\n",
        "         -0.9999, -0.6956, -0.9886, -1.0000, -1.0000, -1.0000,  0.9003, -0.9822,\n",
        "         -0.9932, -0.9944,  0.2616,  0.3027, -0.9998,  1.0000, -1.0000, -0.9834,\n",
        "         -0.5915, -0.5423,  0.8798,  1.0000, -1.0000,  1.0000, -1.0000, -1.0000,\n",
        "         -1.0000,  1.0000,  1.0000, -0.9998, -1.0000, -0.1092,  0.2921, -0.9147,\n",
        "          0.9993, -0.9999, -0.9998, -0.3213,  0.0570,  1.0000, -0.9227,  1.0000,\n",
        "          0.6010, -1.0000, -0.8422,  0.9386, -0.9998,  1.0000,  1.0000,  0.9844,\n",
        "          1.0000, -1.0000, -0.0263,  1.0000,  1.0000,  0.9958,  0.6430,  0.8459,\n",
        "         -1.0000,  1.0000, -0.6944, -0.6967, -1.0000, -1.0000,  0.9893, -1.0000,\n",
        "         -1.0000, -1.0000,  0.9990, -0.9999,  0.7598,  0.9125, -0.9892, -1.0000,\n",
        "         -1.0000, -0.8344, -0.6442,  1.0000, -0.9629, -0.7997, -0.9666, -1.0000,\n",
        "         -1.0000,  0.0574, -1.0000,  1.0000,  0.9998,  1.0000,  1.0000, -1.0000,\n",
        "         -0.9991,  1.0000,  0.5798,  1.0000, -1.0000,  1.0000, -1.0000,  1.0000])\n",
        "\n",
        "# print(target_embd[2].item())\n",
        "\n",
        "for key, value in embeddings_dictionary.items():\n",
        "    # print(cos(target_embd, key))\n",
        "    print(l_emb_size_norm(target_embd, key[0], 128))\n",
        "    # print(key[0])\n",
        "    # break"
      ],
      "metadata": {
        "id": "re4UcPPsxW3a",
        "outputId": "b1799dd3-2419-4746-9eff-0175e3fcddbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "2.53764328524045e+30\n",
            "9.259983011060117e+34\n",
            "3.3042551983784396e+35\n",
            "6.917987137476263e+37\n",
            "7.326616800581911e+37\n",
            "6.72024461335285e+37\n",
            "2.7329090571452416e+33\n",
            "1.3043974091671047e+37\n",
            "8.379807190388248e+36\n",
            "3.505340302858049e+37\n",
            "1.7211751226539518e+33\n",
            "2.4220760006101657e+35\n",
            "8.62047703171003e+34\n",
            "1.2393308063318368e+36\n",
            "2.1845793688840432e+36\n",
            "6.597768905816398e+37\n",
            "6.2143188529606575e+35\n",
            "6.090054078761906e+28\n",
            "1.9371278285573949e+37\n",
            "5.654494188744206e+37\n",
            "1.9810401378257085e+37\n",
            "1.7761254755362758e+37\n",
            "8.877205817401765e+34\n",
            "1.3872662597478206e+36\n",
            "1.4167442400190698e+38\n",
            "1.0782723558235002e+34\n",
            "2.350472958250664e+37\n",
            "5.05008260016604e+37\n",
            "3.654879982050214e+35\n",
            "2.893820271549741e+34\n",
            "1.3422757158177324e+35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hVIs0FVNOHG"
      },
      "source": [
        "### Part (c) -- 2 pt\n",
        "\n",
        "Once you are satisfied with your model, encode your input using\n",
        "the RNN encoder, and sample some sequences from the decoder. The\n",
        "sampling code is provided to you, and performs the computation\n",
        "from the first diagram (without teacher forcing).\n",
        "\n",
        "Note that we are sampling from a multi-nomial distribution described\n",
        "by the logits $z^{(t)}$. For example, if our distribution is [80%, 20%]\n",
        "over a vocabulary of two words, then we will choose the first word\n",
        "with 80% probability and the second word with 20% probability.\n",
        "\n",
        "Call `sample_sequence` at least 5 times, with the default temperature\n",
        "value. Make sure to include the generated sequences in your PDF\n",
        "report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQTLwWxPNOHH"
      },
      "outputs": [],
      "source": [
        "def sample_sequence(model, hidden, max_len=20, temperature=1):\n",
        "    \"\"\"\n",
        "    Return a sequence generated from the model's decoder\n",
        "        - model: an instance of the AutoEncoder model\n",
        "        - hidden: a hidden state (e.g. computed by the encoder)\n",
        "        - max_len: the maximum length of the generated sequence\n",
        "        - temperature: described in Part (d)\n",
        "    \"\"\"\n",
        "    # We'll store our generated sequence here\n",
        "    generated_sequence = []\n",
        "    # Set input to the <BOS> token\n",
        "    inp = torch.Tensor([text_field.vocab.stoi[\"<bos>\"]]).long()\n",
        "    for p in range(max_len):\n",
        "        # compute the output and next hidden unit\n",
        "        output, hidden = model.decode(inp.unsqueeze(0), hidden)\n",
        "        # Sample from the network as a multinomial distribution\n",
        "        output_dist = output.data.view(-1).div(temperature).exp()\n",
        "        top_i = int(torch.multinomial(output_dist, 1)[0])\n",
        "        # Add predicted word to string and use as next input\n",
        "        word = text_field.vocab.itos[top_i]\n",
        "        # Break early if we reach <eos>\n",
        "        if word == \"<eos>\":\n",
        "            break\n",
        "        generated_sequence.append(word)\n",
        "        inp = torch.Tensor([top_i]).long()\n",
        "    return generated_sequence\n",
        "\n",
        "# Your solutions go here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZFJSYBHV_YU"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVKFCePENOHH"
      },
      "source": [
        "### Part (d) -- 3 pt\n",
        "\n",
        "The multi-nomial distribution can be manipulated using the `temperature`\n",
        "setting. This setting can be used to make the distribution \"flatter\" (e.g.\n",
        "more likely to generate different words) or \"peakier\" (e.g. less likely\n",
        "to generate different words).\n",
        "\n",
        "Call `sample_sequence` at least 5 times each for at least 3 different\n",
        "temperature settings (e.g. 1.5, 2, and 5). Explain why we generally\n",
        "don't want the temperature setting to be too **large**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyQuyvjoNOHH"
      },
      "outputs": [],
      "source": [
        "# Include the generated sequences and explanation in your PDF report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iG69llZWumJi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8KpFQWF6KWd"
      },
      "source": [
        "## Count distinct words in title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BddUc_cPoRu8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# This crashes the runtime environment\n",
        "df = pd.read_json(\"/content/arxiv-metadata-oai-snapshot.json\", lines=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hwNTilO6Ogl"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "# Function to extract unique words from a given text\n",
        "def extract_unique_words(text):\n",
        "    # Use regex to split the text into words\n",
        "    words = re.findall(r'\\w+', text.lower())  # Convert to lowercase and split into words\n",
        "    return set(words)\n",
        "\n",
        "\n",
        "# Initialize a Counter to count unique words\n",
        "unique_word_counter = Counter()\n",
        "\n",
        "# Open the JSON file and process it line by line\n",
        "# File from https://www.kaggle.com/datasets/Cornell-University/arxiv/\n",
        "with open('arxiv-metadata-oai-snapshot.json', 'r') as file:\n",
        "    for line in file:\n",
        "        try:\n",
        "            data = json.loads(line)  # Parse the JSON object in each line\n",
        "            if 'title' in data:\n",
        "                title = data['title']\n",
        "                unique_words = extract_unique_words(title)\n",
        "                unique_word_counter.update(unique_words)\n",
        "        except json.JSONDecodeError:\n",
        "            pass  # Skip lines that are not valid JSON\n",
        "\n",
        "# Count the total number of unique words\n",
        "total_unique_words = len(unique_word_counter)\n",
        "\n",
        "# Print the result\n",
        "print(f\"Total number of unique words in paper titles (vocabulary size): {total_unique_words}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZjeIWRwB40P"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to extract the number of words from a given text\n",
        "def count_words(text):\n",
        "    words = re.findall(r'\\w+', text)  # Split the text into words\n",
        "    return len(words)\n",
        "\n",
        "# Initialize a list to store the word counts for titles\n",
        "title_word_counts = []\n",
        "\n",
        "# Open the JSON file and process it line by line\n",
        "with open('arxiv-metadata-oai-snapshot.json', 'r') as file:\n",
        "    for line in file:\n",
        "        try:\n",
        "            data = json.loads(line)  # Parse the JSON object in each line\n",
        "            if 'title' in data:\n",
        "                title = data['title']\n",
        "                word_count = count_words(title)\n",
        "                title_word_counts.append(word_count)\n",
        "        except json.JSONDecodeError:\n",
        "            pass  # Skip lines that are not valid JSON\n",
        "\n",
        "# Create a histogram\n",
        "plt.hist(title_word_counts, bins=20, edgecolor='k')  # Adjust the number of bins as needed\n",
        "plt.title('Word Count Distribution for Research Paper Titles')\n",
        "plt.xlabel('Number of Words in Title')\n",
        "plt.ylabel('Number of Research Papers')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrkJAfkeD6Zb"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "# Function to extract unique words from a given text\n",
        "def extract_unique_words(text):\n",
        "    words = re.findall(r'\\w+', text.lower())  # Convert to lowercase and split into words\n",
        "    return words\n",
        "\n",
        "# Initialize a Counter to count word frequencies\n",
        "word_counter = Counter()\n",
        "\n",
        "# Open the JSON file and process it line by line\n",
        "with open('arxiv-metadata-oai-snapshot.json', 'r') as file:\n",
        "    for line in file:\n",
        "        try:\n",
        "            data = json.loads(line)  # Parse the JSON object in each line\n",
        "            if 'title' in data:\n",
        "                title = data['title']\n",
        "                words = extract_unique_words(title)\n",
        "                word_counter.update(words)\n",
        "        except json.JSONDecodeError:\n",
        "            pass  # Skip lines that are not valid JSON\n",
        "\n",
        "# Get the most common words and their frequencies\n",
        "most_common_words = word_counter.most_common(20)  # You can change 10 to show a different number of words\n",
        "\n",
        "# Extract words and frequencies\n",
        "words, frequencies = zip(*most_common_words)\n",
        "\n",
        "# Create a bar graph\n",
        "plt.bar(words, frequencies)\n",
        "plt.xticks(rotation=45, fontsize=8)\n",
        "plt.title('Top 20 Most Common Words in Research Paper Titles')\n",
        "plt.xlabel('Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}